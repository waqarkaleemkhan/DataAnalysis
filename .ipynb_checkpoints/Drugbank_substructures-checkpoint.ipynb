{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq = pd.read_csv('drugbank_smiles.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drugbank_id</th>\n",
       "      <th>name</th>\n",
       "      <th>cas</th>\n",
       "      <th>smiles</th>\n",
       "      <th>logP ALOGPS</th>\n",
       "      <th>logP ChemAxon</th>\n",
       "      <th>solubility ALOGPS</th>\n",
       "      <th>pKa (strongest acidic)</th>\n",
       "      <th>pKa (strongest basic)</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DB00006</td>\n",
       "      <td>Bivalirudin</td>\n",
       "      <td>128270-60-0</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](CCC(O)=O)NC(=O)[C@...</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>4.64e-02 g/l</td>\n",
       "      <td>2.79</td>\n",
       "      <td>11.88</td>\n",
       "      <td>Bivalirudin is a synthetic 20 residue peptide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DB00007</td>\n",
       "      <td>Leuprolide</td>\n",
       "      <td>53714-56-0</td>\n",
       "      <td>CCNC(=O)[C@@H]1CCCN1C(=O)[C@H](CCCNC(N)=N)NC(=...</td>\n",
       "      <td>1.04</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>3.38e-02 g/l</td>\n",
       "      <td>9.49</td>\n",
       "      <td>11.92</td>\n",
       "      <td>Leuprolide is a synthetic 9-residue peptide an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>DB00014</td>\n",
       "      <td>Goserelin</td>\n",
       "      <td>65807-02-5</td>\n",
       "      <td>CC(C)C[C@H](NC(=O)[C@@H](COC(C)(C)C)NC(=O)[C@H...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>2.83e-02 g/l</td>\n",
       "      <td>9.27</td>\n",
       "      <td>10.82</td>\n",
       "      <td>Goserelin is a synthetic hormone. In men, it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>DB00035</td>\n",
       "      <td>Desmopressin</td>\n",
       "      <td>16679-58-6</td>\n",
       "      <td>NC(=O)CC[C@@H]1NC(=O)[C@H](CC2=CC=CC=C2)NC(=O)...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>1.10e-01 g/l</td>\n",
       "      <td>9.50</td>\n",
       "      <td>11.77</td>\n",
       "      <td>Desmopressin (dDAVP), a synthetic analogue of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DB00050</td>\n",
       "      <td>Cetrorelix</td>\n",
       "      <td>120287-85-6</td>\n",
       "      <td>CC(C)C[C@H](NC(=O)[C@@H](CCCNC(N)=O)NC(=O)[C@H...</td>\n",
       "      <td>1.33</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>6.94e-03 g/l</td>\n",
       "      <td>9.50</td>\n",
       "      <td>11.79</td>\n",
       "      <td>Cetrorelix is a man-made hormone that blocks t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  drugbank_id          name          cas  \\\n",
       "0     DB00006   Bivalirudin  128270-60-0   \n",
       "1     DB00007    Leuprolide   53714-56-0   \n",
       "2     DB00014     Goserelin   65807-02-5   \n",
       "3     DB00035  Desmopressin   16679-58-6   \n",
       "4     DB00050    Cetrorelix  120287-85-6   \n",
       "\n",
       "                                              smiles  logP ALOGPS  \\\n",
       "0  CC[C@H](C)[C@H](NC(=O)[C@H](CCC(O)=O)NC(=O)[C@...        -0.76   \n",
       "1  CCNC(=O)[C@@H]1CCCN1C(=O)[C@H](CCCNC(N)=N)NC(=...         1.04   \n",
       "2  CC(C)C[C@H](NC(=O)[C@@H](COC(C)(C)C)NC(=O)[C@H...         0.30   \n",
       "3  NC(=O)CC[C@@H]1NC(=O)[C@H](CC2=CC=CC=C2)NC(=O)...        -1.00   \n",
       "4  CC(C)C[C@H](NC(=O)[C@@H](CCCNC(N)=O)NC(=O)[C@H...         1.33   \n",
       "\n",
       "   logP ChemAxon solubility ALOGPS  pKa (strongest acidic)  \\\n",
       "0          -14.0      4.64e-02 g/l                    2.79   \n",
       "1           -2.4      3.38e-02 g/l                    9.49   \n",
       "2           -5.2      2.83e-02 g/l                    9.27   \n",
       "3           -6.1      1.10e-01 g/l                    9.50   \n",
       "4           -1.7      6.94e-03 g/l                    9.50   \n",
       "\n",
       "   pKa (strongest basic)                                        description  \n",
       "0                  11.88  Bivalirudin is a synthetic 20 residue peptide ...  \n",
       "1                  11.92  Leuprolide is a synthetic 9-residue peptide an...  \n",
       "2                  10.82  Goserelin is a synthetic hormone. In men, it s...  \n",
       "3                  11.77  Desmopressin (dDAVP), a synthetic analogue of ...  \n",
       "4                  11.79  Cetrorelix is a man-made hormone that blocks t...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8288"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 3",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-428fc462dd7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "df_seq[3].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_codes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import codecs\n",
    "import re\n",
    "import copy\n",
    "import argparse\n",
    "import warnings\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(fobj, is_dict=False):\n",
    "#     Read text and return dictionary that encodes vocabulary\n",
    "    vocab = Counter()\n",
    "    for i, line in enumerate(fobj):\n",
    "        if is_dict:\n",
    "            try:\n",
    "                word, count = line.strip('\\r\\n ').split(' ')\n",
    "            except:\n",
    "                print('Failed reading vocabulary file at line {0}: {1}'.format(i, line))\n",
    "                sys.exit(1)\n",
    "            vocab[word] += int(count)\n",
    "        else:\n",
    "            for word in line.strip('\\r\\n ').split(' '):\n",
    "                if word:\n",
    "                    vocab[word] += 1\n",
    "        \n",
    "    \n",
    "    vocab = Counter()\n",
    "    for word in fobj:\n",
    "        vocab[word] += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pair_statistics(pair, changed, stats, indices):\n",
    "    \"\"\"Minimally update the indices and frequency of symbol pairs\n",
    "    if we merge a pair of symbols, only pairs that overlap with occurrences\n",
    "    of this pair are affected, and need to be updated.\n",
    "    \"\"\"\n",
    "    stats[pair] = 0\n",
    "    indices[pair] = defaultdict(int)\n",
    "    first, second = pair\n",
    "    new_pair = first+second\n",
    "    for j, word, old_word, freq in changed:\n",
    "\n",
    "        # find all instances of pair, and update frequency/indices around it\n",
    "        i = 0\n",
    "        while True:\n",
    "            # find first symbol\n",
    "            try:\n",
    "                i = old_word.index(first, i)\n",
    "            except ValueError:\n",
    "                break\n",
    "            # if first symbol is followed by second symbol, we've found an occurrence of pair (old_word[i:i+2])\n",
    "            if i < len(old_word)-1 and old_word[i+1] == second:\n",
    "                # assuming a symbol sequence \"A B C\", if \"B C\" is merged, reduce the frequency of \"A B\"\n",
    "                if i:\n",
    "                    prev = old_word[i-1:i+1]\n",
    "                    stats[prev] -= freq\n",
    "                    indices[prev][j] -= 1\n",
    "                if i < len(old_word)-2:\n",
    "                    # assuming a symbol sequence \"A B C B\", if \"B C\" is merged, reduce the frequency of \"C B\".\n",
    "                    # however, skip this if the sequence is A B C B C, because the frequency of \"C B\" will be reduced by the previous code block\n",
    "                    if old_word[i+2] != first or i >= len(old_word)-3 or old_word[i+3] != second:\n",
    "                        nex = old_word[i+1:i+3]\n",
    "                        stats[nex] -= freq\n",
    "                        indices[nex][j] -= 1\n",
    "                i += 2\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            try:\n",
    "                # find new pair\n",
    "                i = word.index(new_pair, i)\n",
    "            except ValueError:\n",
    "                break\n",
    "            # assuming a symbol sequence \"A BC D\", if \"B C\" is merged, increase the frequency of \"A BC\"\n",
    "            if i:\n",
    "                prev = word[i-1:i+1]\n",
    "                stats[prev] += freq\n",
    "                indices[prev][j] += 1\n",
    "            # assuming a symbol sequence \"A BC B\", if \"B C\" is merged, increase the frequency of \"BC B\"\n",
    "            # however, if the sequence is A BC BC, skip this step because the count of \"BC BC\" will be incremented by the previous code block\n",
    "            if i < len(word)-1 and word[i+1] != new_pair:\n",
    "                nex = word[i:i+2]\n",
    "                stats[nex] += freq\n",
    "                indices[nex][j] += 1\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_statistics(vocab):\n",
    "    \"\"\"Count frequency of all symbol pairs, and create index\"\"\"\n",
    "\n",
    "    # data structure of pair frequencies\n",
    "    stats = defaultdict(int)\n",
    "\n",
    "    #index from pairs to words\n",
    "    indices = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for i, (word, freq) in enumerate(vocab):\n",
    "        prev_char = word[0]\n",
    "        for char in word[1:]:\n",
    "            stats[prev_char, char] += freq\n",
    "            indices[prev_char, char][i] += 1\n",
    "            prev_char = char\n",
    "\n",
    "    return stats, indices\n",
    "\n",
    "\n",
    "def replace_pair(pair, vocab, indices):\n",
    "    \"\"\"Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'\"\"\"\n",
    "    first, second = pair\n",
    "    pair_str = ''.join(pair)\n",
    "    pair_str = pair_str.replace('\\\\','\\\\\\\\')\n",
    "    changes = []\n",
    "    pattern = re.compile(r'(?<!\\S)' + re.escape(first + ' ' + second) + r'(?!\\S)')\n",
    "    if sys.version_info < (3, 0):\n",
    "        iterator = indices[pair].iteritems()\n",
    "    else:\n",
    "        iterator = indices[pair].items()\n",
    "    for j, freq in iterator:\n",
    "        if freq < 1:\n",
    "            continue\n",
    "        word, freq = vocab[j]\n",
    "        new_word = ' '.join(word)\n",
    "        new_word = pattern.sub(pair_str, new_word)\n",
    "        new_word = tuple(new_word.split(' '))\n",
    "\n",
    "        vocab[j] = (new_word, freq)\n",
    "        changes.append((j, new_word, word, freq))\n",
    "\n",
    "    return changes\n",
    "\n",
    "def prune_stats(stats, big_stats, threshold):\n",
    "    \"\"\"Prune statistics dict for efficiency of max()\n",
    "    The frequency of a symbol pair never increases, so pruning is generally safe\n",
    "    (until we the most frequent pair is less frequent than a pair we previously pruned)\n",
    "    big_stats keeps full statistics for when we need to access pruned items\n",
    "    \"\"\"\n",
    "    for item,freq in list(stats.items()):\n",
    "        if freq < threshold:\n",
    "            del stats[item]\n",
    "            if freq < 0:\n",
    "                big_stats[item] += freq\n",
    "            else:\n",
    "                big_stats[item] = freq\n",
    "\n",
    "\n",
    "def learn_bpe(infile, outfile, num_symbols, min_frequency=2, verbose=False, is_dict=False, total_symbols=False):\n",
    "    \"\"\"Learn num_symbols BPE operations from vocabulary, and write to outfile.\n",
    "    \"\"\"\n",
    "\n",
    "    # version 0.2 changes the handling of the end-of-word token ('</w>');\n",
    "    # version numbering allows bckward compatibility\n",
    "    outfile.write('#version: 0.2\\n')\n",
    "\n",
    "    vocab = get_vocabulary(infile, is_dict)\n",
    "    vocab = dict([(tuple(x[:-1])+(x[-1]+'</w>',) ,y) for (x,y) in vocab.items()])\n",
    "    sorted_vocab = sorted(vocab.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    stats, indices = get_pair_statistics(sorted_vocab)\n",
    "    big_stats = copy.deepcopy(stats)\n",
    "\n",
    "    if total_symbols:\n",
    "        uniq_char_internal = set()\n",
    "        uniq_char_final = set()\n",
    "        for word in vocab:\n",
    "            for char in word[:-1]:\n",
    "                uniq_char_internal.add(char)\n",
    "            uniq_char_final.add(word[-1])\n",
    "        sys.stderr.write('Number of word-internal characters: {0}\\n'.format(len(uniq_char_internal)))\n",
    "        sys.stderr.write('Number of word-final characters: {0}\\n'.format(len(uniq_char_final)))\n",
    "        sys.stderr.write('Reducing number of merge operations by {0}\\n'.format(len(uniq_char_internal) + len(uniq_char_final)))\n",
    "        num_symbols -= len(uniq_char_internal) + len(uniq_char_final)\n",
    "        for i in uniq_char_internal:\n",
    "            vocab_index2units2freq[i] = 0\n",
    "\n",
    "    # threshold is inspired by Zipfian assumption, but should only affect speed\n",
    "    threshold = max(stats.values()) / 10\n",
    "    for i in range(num_symbols):\n",
    "        if stats:\n",
    "            most_frequent = max(stats, key=lambda x: (stats[x], x))\n",
    "\n",
    "        # we probably missed the best pair because of pruning; go back to full statistics\n",
    "        if not stats or (i and stats[most_frequent] < threshold):\n",
    "            prune_stats(stats, big_stats, threshold)\n",
    "            stats = copy.deepcopy(big_stats)\n",
    "            most_frequent = max(stats, key=lambda x: (stats[x], x))\n",
    "            # threshold is inspired by Zipfian assumption, but should only affect speed\n",
    "            threshold = stats[most_frequent] * i/(i+10000.0)\n",
    "            prune_stats(stats, big_stats, threshold)\n",
    "\n",
    "        if stats[most_frequent] < min_frequency:\n",
    "            sys.stderr.write('no pair has frequency >= {0}. Stopping\\n'.format(min_frequency))\n",
    "            break\n",
    "        \n",
    "        #essential\n",
    "        s1 = most_frequent[0].replace('</w>','')\n",
    "        s2 = most_frequent[1].replace('</w>','')\n",
    "        \n",
    "        vocab_index2units2freq[s1+s2] = stats[most_frequent]\n",
    "        \n",
    "        if verbose:\n",
    "            sys.stderr.write('pair {0}: {1} {2} -> {1}{2} (frequency {3})\\n'.format(i, most_frequent[0], most_frequent[1], stats[most_frequent]))\n",
    "        outfile.write('{0} {1}\\n'.format(*most_frequent))\n",
    "        freq_codes.append(most_frequent)\n",
    "        changes = replace_pair(most_frequent, sorted_vocab, indices)\n",
    "        update_pair_statistics(most_frequent, changes, stats, indices)\n",
    "        stats[most_frequent] = 0\n",
    "        if not i % 100:\n",
    "            prune_stats(stats, big_stats, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-7036a927e977>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvocab_index2units2freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./drug_codes_chembl_freq_1500.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w+'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlearn_bpe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_frequency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_symbols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "vocab_index2units2freq = {}\n",
    "seq = (df_seq[0].values)\n",
    "output = open('./drug_codes_chembl_freq_1500.txt', 'w+')\n",
    "learn_bpe(seq, output, 30000, min_frequency=1500, verbose=True, is_dict=False, total_symbols=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subword_nmt.apply_bpe import BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
