{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq = pd.read_csv('drugbank_smiles.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>drugbank_id</td>\n",
       "      <td>name</td>\n",
       "      <td>cas</td>\n",
       "      <td>smiles</td>\n",
       "      <td>logP ALOGPS</td>\n",
       "      <td>logP ChemAxon</td>\n",
       "      <td>solubility ALOGPS</td>\n",
       "      <td>pKa (strongest acidic)</td>\n",
       "      <td>pKa (strongest basic)</td>\n",
       "      <td>description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DB00006</td>\n",
       "      <td>Bivalirudin</td>\n",
       "      <td>128270-60-0</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](CCC(O)=O)NC(=O)[C@...</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-14</td>\n",
       "      <td>4.64e-02 g/l</td>\n",
       "      <td>2.79</td>\n",
       "      <td>11.88</td>\n",
       "      <td>Bivalirudin is a synthetic 20 residue peptide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>DB00007</td>\n",
       "      <td>Leuprolide</td>\n",
       "      <td>53714-56-0</td>\n",
       "      <td>CCNC(=O)[C@@H]1CCCN1C(=O)[C@H](CCCNC(N)=N)NC(=...</td>\n",
       "      <td>1.04</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>3.38e-02 g/l</td>\n",
       "      <td>9.49</td>\n",
       "      <td>11.92</td>\n",
       "      <td>Leuprolide is a synthetic 9-residue peptide an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>DB00014</td>\n",
       "      <td>Goserelin</td>\n",
       "      <td>65807-02-5</td>\n",
       "      <td>CC(C)C[C@H](NC(=O)[C@@H](COC(C)(C)C)NC(=O)[C@H...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>2.83e-02 g/l</td>\n",
       "      <td>9.27</td>\n",
       "      <td>10.82</td>\n",
       "      <td>Goserelin is a synthetic hormone. In men, it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DB00035</td>\n",
       "      <td>Desmopressin</td>\n",
       "      <td>16679-58-6</td>\n",
       "      <td>NC(=O)CC[C@@H]1NC(=O)[C@H](CC2=CC=CC=C2)NC(=O)...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>1.10e-01 g/l</td>\n",
       "      <td>9.5</td>\n",
       "      <td>11.77</td>\n",
       "      <td>Desmopressin (dDAVP), a synthetic analogue of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0             1            2  \\\n",
       "0  drugbank_id          name          cas   \n",
       "1      DB00006   Bivalirudin  128270-60-0   \n",
       "2      DB00007    Leuprolide   53714-56-0   \n",
       "3      DB00014     Goserelin   65807-02-5   \n",
       "4      DB00035  Desmopressin   16679-58-6   \n",
       "\n",
       "                                                   3            4  \\\n",
       "0                                             smiles  logP ALOGPS   \n",
       "1  CC[C@H](C)[C@H](NC(=O)[C@H](CCC(O)=O)NC(=O)[C@...        -0.76   \n",
       "2  CCNC(=O)[C@@H]1CCCN1C(=O)[C@H](CCCNC(N)=N)NC(=...         1.04   \n",
       "3  CC(C)C[C@H](NC(=O)[C@@H](COC(C)(C)C)NC(=O)[C@H...          0.3   \n",
       "4  NC(=O)CC[C@@H]1NC(=O)[C@H](CC2=CC=CC=C2)NC(=O)...           -1   \n",
       "\n",
       "               5                  6                       7  \\\n",
       "0  logP ChemAxon  solubility ALOGPS  pKa (strongest acidic)   \n",
       "1            -14       4.64e-02 g/l                    2.79   \n",
       "2           -2.4       3.38e-02 g/l                    9.49   \n",
       "3           -5.2       2.83e-02 g/l                    9.27   \n",
       "4           -6.1       1.10e-01 g/l                     9.5   \n",
       "\n",
       "                       8                                                  9  \n",
       "0  pKa (strongest basic)                                        description  \n",
       "1                  11.88  Bivalirudin is a synthetic 20 residue peptide ...  \n",
       "2                  11.92  Leuprolide is a synthetic 9-residue peptide an...  \n",
       "3                  10.82  Goserelin is a synthetic hormone. In men, it s...  \n",
       "4                  11.77  Desmopressin (dDAVP), a synthetic analogue of ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC[C@H](C)[C@H](NC(=O)[C@H](CCC(O)=O)NC(=O)[C@H](CCC(O)=O)NC(=O)[C@H](CC1=CC=CC=C1)NC(=O)[C@H](CC(O)=O)NC(=O)CNC(=O)[C@H](CC(N)=O)NC(=O)CNC(=O)CNC(=O)CNC(=O)CNC(=O)[C@@H]1CCCN1C(=O)[C@H](CCCNC(N)=N)NC(=O)[C@@H]1CCCN1C(=O)[C@H](N)CC1=CC=CC=C1)C(=O)N1CCC[C@H]1C(=O)N[C@@H](CCC(O)=O)C(=O)N[C@@H](CCC(O)=O)C(=O)N[C@@H](CC1=CC=C(O)C=C1)C(=O)N[C@@H](CC(C)C)C(O)=O'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_seq[3].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_codes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import codecs\n",
    "import re\n",
    "import copy\n",
    "import argparse\n",
    "import warnings\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(fobj, is_dict=False):\n",
    "    \"\"\"Read text and return dictionary that encodes vocabulary\n",
    "    vocab = Counter()\n",
    "    for i, line in enumerate(fobj):\n",
    "        if is_dict:\n",
    "            try:\n",
    "                word, count = line.strip('\\r\\n ').split(' ')\n",
    "            except:\n",
    "                print('Failed reading vocabulary file at line {0}: {1}'.format(i, line))\n",
    "                sys.exit(1)\n",
    "            vocab[word] += int(count)\n",
    "        else:\n",
    "            for word in line.strip('\\r\\n ').split(' '):\n",
    "                if word:\n",
    "                    vocab[word] += 1\n",
    "        \"\"\"\n",
    "    \n",
    "    vocab = Counter()\n",
    "    for word in fobj:\n",
    "        vocab[word] += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pair_statistics(pair, changed, stats, indices):\n",
    "    \"\"\"Minimally update the indices and frequency of symbol pairs\n",
    "    if we merge a pair of symbols, only pairs that overlap with occurrences\n",
    "    of this pair are affected, and need to be updated.\n",
    "    \"\"\"\n",
    "    stats[pair] = 0\n",
    "    indices[pair] = defaultdict(int)\n",
    "    first, second = pair\n",
    "    new_pair = first+second\n",
    "    for j, word, old_word, freq in changed:\n",
    "\n",
    "        # find all instances of pair, and update frequency/indices around it\n",
    "        i = 0\n",
    "        while True:\n",
    "            # find first symbol\n",
    "            try:\n",
    "                i = old_word.index(first, i)\n",
    "            except ValueError:\n",
    "                break\n",
    "            # if first symbol is followed by second symbol, we've found an occurrence of pair (old_word[i:i+2])\n",
    "            if i < len(old_word)-1 and old_word[i+1] == second:\n",
    "                # assuming a symbol sequence \"A B C\", if \"B C\" is merged, reduce the frequency of \"A B\"\n",
    "                if i:\n",
    "                    prev = old_word[i-1:i+1]\n",
    "                    stats[prev] -= freq\n",
    "                    indices[prev][j] -= 1\n",
    "                if i < len(old_word)-2:\n",
    "                    # assuming a symbol sequence \"A B C B\", if \"B C\" is merged, reduce the frequency of \"C B\".\n",
    "                    # however, skip this if the sequence is A B C B C, because the frequency of \"C B\" will be reduced by the previous code block\n",
    "                    if old_word[i+2] != first or i >= len(old_word)-3 or old_word[i+3] != second:\n",
    "                        nex = old_word[i+1:i+3]\n",
    "                        stats[nex] -= freq\n",
    "                        indices[nex][j] -= 1\n",
    "                i += 2\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            try:\n",
    "                # find new pair\n",
    "                i = word.index(new_pair, i)\n",
    "            except ValueError:\n",
    "                break\n",
    "            # assuming a symbol sequence \"A BC D\", if \"B C\" is merged, increase the frequency of \"A BC\"\n",
    "            if i:\n",
    "                prev = word[i-1:i+1]\n",
    "                stats[prev] += freq\n",
    "                indices[prev][j] += 1\n",
    "            # assuming a symbol sequence \"A BC B\", if \"B C\" is merged, increase the frequency of \"BC B\"\n",
    "            # however, if the sequence is A BC BC, skip this step because the count of \"BC BC\" will be incremented by the previous code block\n",
    "            if i < len(word)-1 and word[i+1] != new_pair:\n",
    "                nex = word[i:i+2]\n",
    "                stats[nex] += freq\n",
    "                indices[nex][j] += 1\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_statistics(vocab):\n",
    "    \"\"\"Count frequency of all symbol pairs, and create index\"\"\"\n",
    "\n",
    "    # data structure of pair frequencies\n",
    "    stats = defaultdict(int)\n",
    "\n",
    "    #index from pairs to words\n",
    "    indices = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for i, (word, freq) in enumerate(vocab):\n",
    "        prev_char = word[0]\n",
    "        for char in word[1:]:\n",
    "            stats[prev_char, char] += freq\n",
    "            indices[prev_char, char][i] += 1\n",
    "            prev_char = char\n",
    "\n",
    "    return stats, indices\n",
    "\n",
    "\n",
    "def replace_pair(pair, vocab, indices):\n",
    "    \"\"\"Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'\"\"\"\n",
    "    first, second = pair\n",
    "    pair_str = ''.join(pair)\n",
    "    pair_str = pair_str.replace('\\\\','\\\\\\\\')\n",
    "    changes = []\n",
    "    pattern = re.compile(r'(?<!\\S)' + re.escape(first + ' ' + second) + r'(?!\\S)')\n",
    "    if sys.version_info < (3, 0):\n",
    "        iterator = indices[pair].iteritems()\n",
    "    else:\n",
    "        iterator = indices[pair].items()\n",
    "    for j, freq in iterator:\n",
    "        if freq < 1:\n",
    "            continue\n",
    "        word, freq = vocab[j]\n",
    "        new_word = ' '.join(word)\n",
    "        new_word = pattern.sub(pair_str, new_word)\n",
    "        new_word = tuple(new_word.split(' '))\n",
    "\n",
    "        vocab[j] = (new_word, freq)\n",
    "        changes.append((j, new_word, word, freq))\n",
    "\n",
    "    return changes\n",
    "\n",
    "def prune_stats(stats, big_stats, threshold):\n",
    "    \"\"\"Prune statistics dict for efficiency of max()\n",
    "    The frequency of a symbol pair never increases, so pruning is generally safe\n",
    "    (until we the most frequent pair is less frequent than a pair we previously pruned)\n",
    "    big_stats keeps full statistics for when we need to access pruned items\n",
    "    \"\"\"\n",
    "    for item,freq in list(stats.items()):\n",
    "        if freq < threshold:\n",
    "            del stats[item]\n",
    "            if freq < 0:\n",
    "                big_stats[item] += freq\n",
    "            else:\n",
    "                big_stats[item] = freq\n",
    "\n",
    "\n",
    "def learn_bpe(infile, outfile, num_symbols, min_frequency=2, verbose=False, is_dict=False, total_symbols=False):\n",
    "    \"\"\"Learn num_symbols BPE operations from vocabulary, and write to outfile.\n",
    "    \"\"\"\n",
    "\n",
    "    # version 0.2 changes the handling of the end-of-word token ('</w>');\n",
    "    # version numbering allows bckward compatibility\n",
    "    outfile.write('#version: 0.2\\n')\n",
    "\n",
    "    vocab = get_vocabulary(infile, is_dict)\n",
    "    vocab = dict([(tuple(x[:-1])+(x[-1]+'</w>',) ,y) for (x,y) in vocab.items()])\n",
    "    sorted_vocab = sorted(vocab.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    stats, indices = get_pair_statistics(sorted_vocab)\n",
    "    big_stats = copy.deepcopy(stats)\n",
    "\n",
    "    if total_symbols:\n",
    "        uniq_char_internal = set()\n",
    "        uniq_char_final = set()\n",
    "        for word in vocab:\n",
    "            for char in word[:-1]:\n",
    "                uniq_char_internal.add(char)\n",
    "            uniq_char_final.add(word[-1])\n",
    "        sys.stderr.write('Number of word-internal characters: {0}\\n'.format(len(uniq_char_internal)))\n",
    "        sys.stderr.write('Number of word-final characters: {0}\\n'.format(len(uniq_char_final)))\n",
    "        sys.stderr.write('Reducing number of merge operations by {0}\\n'.format(len(uniq_char_internal) + len(uniq_char_final)))\n",
    "        num_symbols -= len(uniq_char_internal) + len(uniq_char_final)\n",
    "        for i in uniq_char_internal:\n",
    "            vocab_index2units2freq[i] = 0\n",
    "\n",
    "    # threshold is inspired by Zipfian assumption, but should only affect speed\n",
    "    threshold = max(stats.values()) / 10\n",
    "    for i in range(num_symbols):\n",
    "        if stats:\n",
    "            most_frequent = max(stats, key=lambda x: (stats[x], x))\n",
    "\n",
    "        # we probably missed the best pair because of pruning; go back to full statistics\n",
    "        if not stats or (i and stats[most_frequent] < threshold):\n",
    "            prune_stats(stats, big_stats, threshold)\n",
    "            stats = copy.deepcopy(big_stats)\n",
    "            most_frequent = max(stats, key=lambda x: (stats[x], x))\n",
    "            # threshold is inspired by Zipfian assumption, but should only affect speed\n",
    "            threshold = stats[most_frequent] * i/(i+10000.0)\n",
    "            prune_stats(stats, big_stats, threshold)\n",
    "\n",
    "        if stats[most_frequent] < min_frequency:\n",
    "            sys.stderr.write('no pair has frequency >= {0}. Stopping\\n'.format(min_frequency))\n",
    "            break\n",
    "        \n",
    "        #essential\n",
    "        s1 = most_frequent[0].replace('</w>','')\n",
    "        s2 = most_frequent[1].replace('</w>','')\n",
    "        \n",
    "        vocab_index2units2freq[s1+s2] = stats[most_frequent]\n",
    "        \n",
    "        if verbose:\n",
    "            sys.stderr.write('pair {0}: {1} {2} -> {1}{2} (frequency {3})\\n'.format(i, most_frequent[0], most_frequent[1], stats[most_frequent]))\n",
    "        outfile.write('{0} {1}\\n'.format(*most_frequent))\n",
    "        freq_codes.append(most_frequent)\n",
    "        changes = replace_pair(most_frequent, sorted_vocab, indices)\n",
    "        update_pair_statistics(most_frequent, changes, stats, indices)\n",
    "        stats[most_frequent] = 0\n",
    "        if not i % 100:\n",
    "            prune_stats(stats, big_stats, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of word-internal characters: 22\n",
      "Number of word-final characters: 11\n",
      "Reducing number of merge operations by 33\n",
      "pair 0: D B -> DB (frequency 8288)\n",
      "pair 1: DB 0 -> DB0 (frequency 5949)\n",
      "pair 2: DB 1 -> DB1 (frequency 2339)\n",
      "no pair has frequency >= 1500. Stopping\n"
     ]
    }
   ],
   "source": [
    "vocab_index2units2freq = {}\n",
    "seq = (df_seq[0].values)\n",
    "output = open('./drug_codes_chembl_freq_1500.txt', 'w+')\n",
    "learn_bpe(seq, output, 30000, min_frequency=1500, verbose=True, is_dict=False, total_symbols=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
